{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "logo"
    ]
   },
   "source": [
    "[![logo](https://climate.copernicus.eu/sites/default/files/custom-uploads/branding/LogoLine_horizon_C3S.png)](https://climate.copernicus.eu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and preprocessing data for agroclimatic indicators\n",
    "\n",
    "This notebook shows how to download and preprocess climate model data for bias correction and further use. To apply a bias adjustment method and generate agroclimatinc indicators, three datasets are needed: \n",
    "1) Observation or reanalysis data;\n",
    "2) Historical climate model data over the same reference period that observations are available for; and\n",
    "3) Climate model data for a future, or more generally, application period that is to be used for generating agroclimatic indicators. \n",
    "\n",
    "Here we will download and preprocess CMIP6 data as climate model input and AgERA5 as reanalysis dataset from the Climate Data Store (CDS).\n",
    "\n",
    "There are many ways to access climate data on different temporal or spatial resolutions. This notebook is meant to illustrate one possible way to download data at daily resolution which is currently the primary temporal resolution supported in ibicus, although some can be applied at monthly resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing necessary libraries\n",
    "\n",
    "In order to run this notebook, the python environment has to be prepared by installing a number of additional libraries:\n",
    "* `cdsapi` (https://pypi.org/project/cdsapi/) - Using the CDS API requests to download data\n",
    "* `xarray` (https://pypi.org/project/xarray/) - Working with N-D labeled arrays and datasets\n",
    "* `netCDF4` (https://pypi.org/project/netCDF4/) - backend for reading and writing NetCDF files\n",
    "* `dask` (https://pypi.org/project/dask/) - Parallel processing and data chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cdsapi in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (0.7.5)\n",
      "Requirement already satisfied: xarray in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (2025.3.0)\n",
      "Requirement already satisfied: netCDF4 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (1.7.2)\n",
      "Collecting dask\n",
      "  Downloading dask-2025.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: datapi in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from cdsapi) (0.3.0)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from cdsapi) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from cdsapi) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from xarray) (2.2.4)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from xarray) (24.2)\n",
      "Requirement already satisfied: pandas>=2.1 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from xarray) (2.2.3)\n",
      "Requirement already satisfied: cftime in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from netCDF4) (1.6.4.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from netCDF4) (2025.1.31)\n",
      "Collecting click>=8.1 (from dask)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting cloudpickle>=3.0.0 (from dask)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting partd>=1.4.0 (from dask)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from dask) (6.0.2)\n",
      "Collecting toolz>=0.10.0 (from dask)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from click>=8.1->dask) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from pandas>=2.1->xarray) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from pandas>=2.1->xarray) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from pandas>=2.1->xarray) (2025.2)\n",
      "Collecting locket (from partd>=1.4.0->dask)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from requests>=2.5.0->cdsapi) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from requests>=2.5.0->cdsapi) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from requests>=2.5.0->cdsapi) (2.3.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from datapi->cdsapi) (25.3.0)\n",
      "Requirement already satisfied: multiurl>=0.3.2 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from datapi->cdsapi) (0.3.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from datapi->cdsapi) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\girza001\\.conda\\envs\\agroclim\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray) (1.17.0)\n",
      "Downloading dask-2025.3.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 18.7 MB/s eta 0:00:00\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: toolz, locket, fsspec, cloudpickle, click, partd, dask\n",
      "Successfully installed click-8.1.8 cloudpickle-3.1.1 dask-2025.3.0 fsspec-2025.3.0 locket-1.0.0 partd-1.4.2 toolz-1.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install cdsapi xarray netCDF4 dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi              # Downloading data via CDS API\n",
    "import zipfile             # Extracting downloaded .zip files\n",
    "from pathlib import Path   # Working with system paths and directories\n",
    "\n",
    "import xarray as xr        # Working with data arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let us prepare the directory structure for storing the downloaded data. \n",
    "\n",
    "*Choose the parent directory where all data will be stored*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_PATH = \"./Data/agroclim_data\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory structure, starting at the parent path\n",
    "parent_path = Path(PARENT_PATH)\n",
    "\n",
    "# Historical data directories\n",
    "hist_model_path = parent_path / \"historical_model_data\"\n",
    "hist_obs_path = parent_path / \"historical_observation_data\"\n",
    "\n",
    "# Future projection data directory\n",
    "future_model_path = parent_path / \"future_model_data\"\n",
    "\n",
    "# Create the above-defined directories\n",
    "hist_model_path.mkdir(parents=True, exist_ok=True)\n",
    "hist_obs_path.mkdir(parents=True, exist_ok=True)\n",
    "future_model_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Downloading climate model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To request climate data from the Climate Data Store (CDS) we will use the CDS API.\n",
    "\n",
    "We make use of the option to manually set the CDS API credentials. First, you have to set two variables: URL and KEY which build together your CDS API key. The string of characters that make up your KEY include your personal User ID and CDS API key. \n",
    "\n",
    "*To obtain these, first register or login to the CDS (http://cds.climate.copernicus.eu), then visit https://cds.climate.copernicus.eu/api-how-to and copy the string of characters listed after \"key:\". Replace the ######### below with your key.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://cds.climate.copernicus.eu/api'\n",
    "KEY = '#########' # enter your key instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:30:15,252 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-03-25 12:30:15,253 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n"
     ]
    }
   ],
   "source": [
    "# Initialise CDS API client\n",
    "cds_api = cdsapi.Client(url=URL, key=KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us select model and variable parameters we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model and future projection experiment\n",
    "MODEL = 'ec_earth3_cc'\n",
    "EXPERIMENT_FUTURE = 'ssp5_8_5'\n",
    "\n",
    "# Choose climate variables to extract\n",
    "VARIABLES = [\n",
    "    \"near_surface_air_temperature\", \n",
    "    \"daily_minimum_near_surface_air_temperature\", \n",
    "    \"daily_maximum_near_surface_air_temperature\",\n",
    "    \"precipitation\"\n",
    "]\n",
    "\n",
    "# Choose area to extract\n",
    "AREA = [44, -10, 36, 1] # Approximate bounds of the Iberian Peninsula\n",
    "\n",
    "# Choose years to download for historical data\n",
    "# 2000 - 2013\n",
    "YEARS_HIST = [\n",
    "    \"2000\",\n",
    "    \"2001\",\n",
    "    \"2002\",\n",
    "    \"2003\",\n",
    "    \"2004\",\n",
    "    \"2005\",\n",
    "    \"2006\",\n",
    "    \"2007\",\n",
    "    \"2008\",\n",
    "    \"2009\",\n",
    "    \"2010\",\n",
    "    \"2011\",\n",
    "    \"2012\",\n",
    "    \"2013\",\n",
    "]\n",
    "\n",
    "# Choose months to download for historical data\n",
    "# (all 12 months)\n",
    "MONTHS_HIST = [\n",
    "    \"01\", \"02\", \"03\",\n",
    "    \"04\", \"05\", \"06\",\n",
    "    \"07\", \"08\", \"09\",\n",
    "    \"10\", \"11\", \"12\"\n",
    "]\n",
    "\n",
    "# Choose days to download for historical data\n",
    "# (all 31 days)\n",
    "DAYS_HIST = [\n",
    "    \"01\", \"02\", \"03\",\n",
    "    \"04\", \"05\", \"06\",\n",
    "    \"07\", \"08\", \"09\",\n",
    "    \"10\", \"11\", \"12\",\n",
    "    \"13\", \"14\", \"15\",\n",
    "    \"16\", \"17\", \"18\",\n",
    "    \"19\", \"20\", \"21\",\n",
    "    \"22\", \"23\", \"24\",\n",
    "    \"25\", \"26\", \"27\",\n",
    "    \"28\", \"29\", \"30\",\n",
    "    \"31\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose years to download for future projection data\n",
    "# 2040-2049\n",
    "YEARS_FUTURE = [\n",
    "    \"2040\",\n",
    "    \"2041\",\n",
    "    \"2042\",\n",
    "    \"2043\",\n",
    "    \"2044\",\n",
    "    \"2045\",\n",
    "    \"2046\",\n",
    "    \"2047\",\n",
    "    \"2048\",\n",
    "    \"2049\",\n",
    "]\n",
    "\n",
    "# Months and days are the same as historical data.\n",
    "# (all possible months and all possible days)\n",
    "MONTHS_FUTURE = MONTHS_HIST\n",
    "DAYS_FUTURE = DAYS_HIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.1.1 Downloading historical climate model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the cell below will retrieve the historical climate model data for the selected set of climate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading near_surface_air_temperature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:23:30,677 INFO Request ID is 6bd186df-b493-4eac-957b-018254cbdb91\n",
      "2025-03-20 12:23:30,779 INFO status has been updated to accepted\n",
      "2025-03-20 12:23:38,173 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "d86cc2672760b93d6b98ff1e31b0330.zip:   0%|          | 0.00/4.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading daily_minimum_near_surface_air_temperature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:23:39,766 INFO Request ID is 8d43cc8b-f49e-4888-b2a7-de2a2984b472\n",
      "2025-03-20 12:23:39,850 INFO status has been updated to accepted\n",
      "2025-03-20 12:23:47,206 INFO status has been updated to running\n",
      "2025-03-20 12:23:52,325 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "d8ba18abd30364299ed96431ce38e913.zip:   0%|          | 0.00/4.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading daily_maximum_near_surface_air_temperature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:23:56,900 INFO Request ID is 3defb251-28cf-4445-9f59-fed07f6f4b8d\n",
      "2025-03-20 12:23:56,961 INFO status has been updated to accepted\n",
      "2025-03-20 12:24:00,866 INFO status has been updated to running\n",
      "2025-03-20 12:24:04,308 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "50d1e3745166e5a6e69d93fe08d63b9c.zip:   0%|          | 0.00/4.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading precipitation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:24:06,555 INFO Request ID is 5cf48ba1-6a3b-464e-aa8b-6d7767990673\n",
      "2025-03-20 12:24:06,617 INFO status has been updated to accepted\n",
      "2025-03-20 12:24:13,980 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "48559aa899a33eed105c31108f03264.zip:   0%|          | 0.00/3.97M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop over selected variables\n",
    "for variable in VARIABLES:\n",
    "    print(f\"Downloading {variable}...\")\n",
    "    \n",
    "    # Choose a filename for the historical model data\n",
    "    filename = f\"{variable}_historical_{MODEL}.zip\"\n",
    "    filepath = hist_model_path/filename\n",
    "\n",
    "    # Choose a directory name for extracting the downloaded data into\n",
    "    extract_dir = f\"{variable}_historical_{MODEL}_extracted\"\n",
    "    extract_path = hist_model_path/extract_dir\n",
    "\n",
    "    # Download the zip file with selected data\n",
    "    cds_api.retrieve(\n",
    "        name = 'projections-cmip6',\n",
    "        request = {\n",
    "            \"temporal_resolution\": \"daily\",\n",
    "            \"model\": MODEL,\n",
    "            \"experiment\": \"historical\",\n",
    "            \"variable\": variable,\n",
    "            \"year\": YEARS_HIST,\n",
    "            \"month\": MONTHS_HIST,\n",
    "            \"day\": DAYS_HIST,\n",
    "            \"area\": AREA\n",
    "        },\n",
    "        target = filepath\n",
    "    )\n",
    "\n",
    "    # Extract the zip file\n",
    "    # (\"//?/\" to prevent issues with long file paths in Windows)\n",
    "    with zipfile.ZipFile(r\"//?/\"+f\"{filepath.resolve()}\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(r\"//?/\"+f\"{extract_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.1.2 Downloading future climate model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go through the same steps to download climate data in the future or application period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading near_surface_air_temperature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:26:49,497 INFO Request ID is 0b2688fa-5a3e-47f8-9abc-de2cfcd01ed5\n",
      "2025-03-20 12:26:49,573 INFO status has been updated to accepted\n",
      "2025-03-20 12:26:56,954 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "e0c7104e5173dd662379ef467b1a69fa.zip:   0%|          | 0.00/3.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading daily_minimum_near_surface_air_temperature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:26:58,636 INFO Request ID is 959b459b-9c2d-4998-8a3d-d03052698044\n",
      "2025-03-20 12:26:58,732 INFO status has been updated to accepted\n",
      "2025-03-20 12:27:06,087 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eb1a6234f32be384edb4bf8b7bad545b.zip:   0%|          | 0.00/3.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading daily_maximum_near_surface_air_temperature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:27:07,529 INFO Request ID is 21747f8b-2b02-4ee0-923a-8410b65f1d0f\n",
      "2025-03-20 12:27:07,640 INFO status has been updated to accepted\n",
      "2025-03-20 12:27:20,118 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cc0b33279047bfe5907cdeac82512ca9.zip:   0%|          | 0.00/3.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading precipitation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:27:22,019 INFO Request ID is 344b066e-ba01-4d5a-b39d-dc71c68c568b\n",
      "2025-03-20 12:27:22,090 INFO status has been updated to accepted\n",
      "2025-03-20 12:27:25,970 INFO status has been updated to running\n",
      "2025-03-20 12:27:29,411 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "d3fe8b8442814653a17ff123c261f657.zip:   0%|          | 0.00/2.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop over selected variables\n",
    "for variable in VARIABLES:\n",
    "    print(f\"Downloading {variable}...\")\n",
    "    \n",
    "    # Choose a filename for the historical model data\n",
    "    filename = f\"{variable}_future_{MODEL}_{EXPERIMENT_FUTURE}.zip\"\n",
    "    filepath = future_model_path/filename\n",
    "\n",
    "    # Choose a directory name for extracting the downloaded data into\n",
    "    extract_dir = f\"{variable}_future_{MODEL}_{EXPERIMENT_FUTURE}_extracted\"\n",
    "    extract_path = future_model_path/extract_dir\n",
    "\n",
    "    # Download the zip file with selected data\n",
    "    cds_api.retrieve(\n",
    "        name = 'projections-cmip6',\n",
    "        request = {\n",
    "            \"temporal_resolution\": \"daily\",\n",
    "            \"model\": MODEL,\n",
    "            \"experiment\": EXPERIMENT_FUTURE,\n",
    "            \"variable\": variable,\n",
    "            \"year\": YEARS_FUTURE,\n",
    "            \"month\": MONTHS_FUTURE,\n",
    "            \"day\": DAYS_FUTURE,\n",
    "            \"area\": AREA\n",
    "        },\n",
    "        target = filepath\n",
    "    )\n",
    "\n",
    "    # Extract the zip file\n",
    "    # (\"//?/\" to prevent issues with long file paths in Windows)\n",
    "    with zipfile.ZipFile(r\"//?/\"+f\"{filepath.resolve()}\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(r\"//?/\"+f\"{extract_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Downloading historical observation (reanalysis) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to download historical observation (reanalysis) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Downloading AgERA5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download AgERA5 on daily temporal resolution.\n",
    "\n",
    "The output of this application is a separate netCDF file for chosen daily statistic for each month for each year. We then concatenate these files manually. First we need to make some selections (make sure the data chosen here is consistent with the cm data pulled above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a combination of climate variables and corresponding statistics\n",
    "VAR_STATS_AGERA = [\n",
    "    # (min, mean, max) near surface air temperature\n",
    "    {\n",
    "        \"variable\":\"2m_temperature\",\n",
    "        \"statistics\":[\n",
    "            \"24_hour_minimum\",\n",
    "            \"24_hour_mean\",\n",
    "            \"24_hour_maximum\",\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # precipitation flux (no statistic applies)\n",
    "    {\n",
    "        \"variable\":\"precipitation_flux\",\n",
    "        \"statistics\":[\"\"]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AgERA5 data has to be downloaded for each year and each statistic separately, in order to keep request size manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2m_temperature...\n",
      "Statistic: 24_hour_minimum\n",
      "----- Requesting year: 2000 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2000.zip already exists. Skipping...\n",
      "----- Requesting year: 2001 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2001.zip already exists. Skipping...\n",
      "----- Requesting year: 2002 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2002.zip already exists. Skipping...\n",
      "----- Requesting year: 2003 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2003.zip already exists. Skipping...\n",
      "----- Requesting year: 2004 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2004.zip already exists. Skipping...\n",
      "----- Requesting year: 2005 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2005.zip already exists. Skipping...\n",
      "----- Requesting year: 2006 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2006.zip already exists. Skipping...\n",
      "----- Requesting year: 2007 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2007.zip already exists. Skipping...\n",
      "----- Requesting year: 2008 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2008.zip already exists. Skipping...\n",
      "----- Requesting year: 2009 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2009.zip already exists. Skipping...\n",
      "----- Requesting year: 2010 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2010.zip already exists. Skipping...\n",
      "----- Requesting year: 2011 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2011.zip already exists. Skipping...\n",
      "----- Requesting year: 2012 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2012.zip already exists. Skipping...\n",
      "----- Requesting year: 2013 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_minimum_historical_obs_2013.zip already exists. Skipping...\n",
      "Statistic: 24_hour_mean\n",
      "----- Requesting year: 2000 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2000.zip already exists. Skipping...\n",
      "----- Requesting year: 2001 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2001.zip already exists. Skipping...\n",
      "----- Requesting year: 2002 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2002.zip already exists. Skipping...\n",
      "----- Requesting year: 2003 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2003.zip already exists. Skipping...\n",
      "----- Requesting year: 2004 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2004.zip already exists. Skipping...\n",
      "----- Requesting year: 2005 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2005.zip already exists. Skipping...\n",
      "----- Requesting year: 2006 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2006.zip already exists. Skipping...\n",
      "----- Requesting year: 2007 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2007.zip already exists. Skipping...\n",
      "----- Requesting year: 2008 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2008.zip already exists. Skipping...\n",
      "----- Requesting year: 2009 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2009.zip already exists. Skipping...\n",
      "----- Requesting year: 2010 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2010.zip already exists. Skipping...\n",
      "----- Requesting year: 2011 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2011.zip already exists. Skipping...\n",
      "----- Requesting year: 2012 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2012.zip already exists. Skipping...\n",
      "----- Requesting year: 2013 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_mean_historical_obs_2013.zip already exists. Skipping...\n",
      "Statistic: 24_hour_maximum\n",
      "----- Requesting year: 2000 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2000.zip already exists. Skipping...\n",
      "----- Requesting year: 2001 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2001.zip already exists. Skipping...\n",
      "----- Requesting year: 2002 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2002.zip already exists. Skipping...\n",
      "----- Requesting year: 2003 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2003.zip already exists. Skipping...\n",
      "----- Requesting year: 2004 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2004.zip already exists. Skipping...\n",
      "----- Requesting year: 2005 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2005.zip already exists. Skipping...\n",
      "----- Requesting year: 2006 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2006.zip already exists. Skipping...\n",
      "----- Requesting year: 2007 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2007.zip already exists. Skipping...\n",
      "----- Requesting year: 2008 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2008.zip already exists. Skipping...\n",
      "----- Requesting year: 2009 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2009.zip already exists. Skipping...\n",
      "----- Requesting year: 2010 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2010.zip already exists. Skipping...\n",
      "----- Requesting year: 2011 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2011.zip already exists. Skipping...\n",
      "----- Requesting year: 2012 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2012.zip already exists. Skipping...\n",
      "----- Requesting year: 2013 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\2m_temperature_24_hour_maximum_historical_obs_2013.zip already exists. Skipping...\n",
      "Downloading precipitation_flux...\n",
      "Statistic: \n",
      "----- Requesting year: 2000 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2000.zip already exists. Skipping...\n",
      "----- Requesting year: 2001 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2001.zip already exists. Skipping...\n",
      "----- Requesting year: 2002 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2002.zip already exists. Skipping...\n",
      "----- Requesting year: 2003 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2003.zip already exists. Skipping...\n",
      "----- Requesting year: 2004 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2004.zip already exists. Skipping...\n",
      "----- Requesting year: 2005 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2005.zip already exists. Skipping...\n",
      "----- Requesting year: 2006 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2006.zip already exists. Skipping...\n",
      "----- Requesting year: 2007 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2007.zip already exists. Skipping...\n",
      "----- Requesting year: 2008 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2008.zip already exists. Skipping...\n",
      "----- Requesting year: 2009 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2009.zip already exists. Skipping...\n",
      "----- Requesting year: 2010 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2010.zip already exists. Skipping...\n",
      "----- Requesting year: 2011 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2011.zip already exists. Skipping...\n",
      "----- Requesting year: 2012 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2012.zip already exists. Skipping...\n",
      "----- Requesting year: 2013 -----\n",
      "Data\\agroclim_data\\historical_observation_data\\precipitation_flux__historical_obs_2013.zip already exists. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Loop over different climate variables\n",
    "for var_stat in VAR_STATS_AGERA:\n",
    "    variable = var_stat[\"variable\"]\n",
    "    statistics = var_stat[\"statistics\"]\n",
    "    \n",
    "    print(f\"Downloading {variable}...\")\n",
    "\n",
    "    # Loop over relevant statistics for the current variable\n",
    "    for statistic in statistics:\n",
    "        print(f\"Statistic: {statistic}\")\n",
    "\n",
    "        # Loop over relevant years\n",
    "        for year in YEARS_HIST:\n",
    "            print(f\"----- Requesting year: {year} -----\")\n",
    "\n",
    "            # Choose a filename for the historical observation data\n",
    "            filename = f\"{variable}_{statistic}_historical_obs_{year}.zip\"\n",
    "            filepath = hist_obs_path/filename\n",
    "            \n",
    "            # Choose a directory name for extracting the downloaded data into\n",
    "            extract_dir = f\"{variable}_{statistic}_historical_obs_extracted\"\n",
    "            extract_path = hist_obs_path/extract_dir\n",
    "            \n",
    "            # Download the zip file with selected data\n",
    "            if filepath.exists():\n",
    "                # In case we get a CDS API error, we can rerun the cell without re-downloading already present files\n",
    "                print(f\"{filepath} already exists. Skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                cds_api.retrieve(\n",
    "                    name = \"sis-agrometeorological-indicators\",\n",
    "                    request = {\n",
    "                        \"variable\": variable,\n",
    "                        \"statistic\": [statistic],\n",
    "                        \"year\": f\"{year}\",\n",
    "                        \"month\": MONTHS_HIST,\n",
    "                        \"day\": DAYS_HIST,\n",
    "                        \"area\": AREA,\n",
    "                        \"version\":\"1_1\"\n",
    "                    },\n",
    "                    target = filepath\n",
    "                )\n",
    "            \n",
    "                # Extract the zip file\n",
    "                # (\"//?/\" to prevent issues with long file paths in Windows)\n",
    "                with zipfile.ZipFile(r\"//?/\"+f\"{filepath.resolve()}\", 'r') as zip_ref:\n",
    "                    zip_ref.extractall(r\"//?/\"+f\"{extract_path.resolve()}\")\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "author": "",
  "celltoolbar": "Tags",
  "content_type": "Software & code",
  "data_access": "",
  "deployment": {
   "deployment_name": {
    "deployment_service": {
     "link": "",
     "service_contact": "",
     "service_provider": ""
    },
    "git": {
     "link": "",
     "service_contact": "",
     "service_provider": ""
    }
   }
  },
  "description": "",
  "image": "",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "license": "",
  "metadata_schema_version": "",
  "originator": "",
  "tags": {
   "category": "",
   "data_product": "",
   "data_provider": "",
   "data_type": "",
   "subtheme": "",
   "theme": "",
   "variable": ""
  },
  "title": "",
  "version": "",
  "version_date": ""
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
